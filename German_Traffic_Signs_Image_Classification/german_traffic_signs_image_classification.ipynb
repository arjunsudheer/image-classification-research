{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "eWvjlhg1rwo1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca0dd9ba-747f-49e2-be3d-31edc5d71a40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "# import the dataset files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "\n",
        "# change directory to the Train folder\n",
        "os.chdir('/content/gdrive/MyDrive/Colab_Notebooks/Project_Engineering_Success/German_Traffic_Signs_Image_Classification/Train')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# used to read images from files\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "num_classes = 43\n",
        "data = []\n",
        "labels = []\n",
        "curr_path = os.getcwd()\n",
        "\n",
        "# access each of the 43 subdirectories\n",
        "for i in range(num_classes):\n",
        "  path = os.path.join(curr_path, str(i))\n",
        "  images = os.listdir(path)\n",
        "  # access each picture within each subdirectory\n",
        "  for pic in images:\n",
        "    try:\n",
        "      image = Image.open(path + \"/\" + pic)\n",
        "      resize_image = image.resize((30, 30))\n",
        "      numpy_image = np.array(resize_image)\n",
        "      # grayscale_image = np.reshape(numpy_image[:,:,1], (900, 1))\n",
        "      # grayscale_image = np.reshape(numpy_image[:,:,1], (30, 30, 1))\n",
        "      # flattened_image = grayscale_image.flatten()\n",
        "      # data = np.append(data, flattened_image, axis=0)\n",
        "      data.append(numpy_image)\n",
        "      labels.append(i)\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O77nt3luClW_",
        "outputId": "1587b8bb-dc1f-4d95-f35c-669df9b1f0ce"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert data and labels arrays to numpy arrays\n",
        "data = np.array(data)\n",
        "labels = np.array(labels)"
      ],
      "metadata": {
        "id": "YpVYCaQuQv8d"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save the data and labels arrays\n",
        "np.save('/content/gdrive/MyDrive/Colab_Notebooks/Project_Engineering_Success/German_Traffic_Signs_Image_Classification/training/data.npy', data)\n",
        "np.save('/content/gdrive/MyDrive/Colab_Notebooks/Project_Engineering_Success/German_Traffic_Signs_Image_Classification/training/labels.npy', labels)"
      ],
      "metadata": {
        "id": "hMbTsao36M4a"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the data and labels array\n",
        "data = np.load('/content/gdrive/MyDrive/Colab_Notebooks/Project_Engineering_Success/German_Traffic_Signs_Image_Classification/training/data.npy')\n",
        "labels = np.load('/content/gdrive/MyDrive/Colab_Notebooks/Project_Engineering_Success/German_Traffic_Signs_Image_Classification/training/labels.npy')"
      ],
      "metadata": {
        "id": "p7mYcjaY6fYl"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.shape, labels.shape)\n",
        "print(data.size, labels.size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fv3YCUFi7BnZ",
        "outputId": "3d2e8eec-3283-4df4-959c-09a442605374"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(39519, 30, 30, 3) (39519,)\n",
            "106701300 39519\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# used to split the training data into train and test files\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# use 20% of files for testing, and 80% for training\n",
        "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2)"
      ],
      "metadata": {
        "id": "4eU7YXmpvty-"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"x_test shape:\", x_test.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ],
      "metadata": {
        "id": "XqGbD-RP-BqK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7d814af-6799-4595-d62b-c0dcd7565b3d"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (31615, 30, 30, 3)\n",
            "y_train shape: (31615,)\n",
            "x_test shape: (7904, 30, 30, 3)\n",
            "y_test shape: (7904,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "# Convert the image arrays to binary matrices (one hot encoding)\n",
        "  # One hot encoding associates categorical data with a number instead\n",
        "  # In this case, we are associating the name of the sign with a number from 1-43 (since we have 43 classes)\n",
        "y_train_enc = to_categorical(y_train, 43)\n",
        "y_test_enc = to_categorical(y_test, 43)"
      ],
      "metadata": {
        "id": "JAbnYjIExXqI"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout\n",
        "\n",
        "# model = Sequential([\n",
        "#     Dense(units=16, input_shape=x_train.shape[1:], activation='relu'),\n",
        "#     Dense(units=32, activation='relu'),\n",
        "#     # use 43 units because there are 43 classes in the German Traffic Signals Dataset\n",
        "#     Dense(units=43, activation='softmax')\n",
        "# ])\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(filters=32, kernel_size=(5, 5), activation='relu', input_shape=x_train.shape[1:]),\n",
        "    Conv2D(filters=32, kernel_size=(5, 5), activation='relu'),\n",
        "    MaxPool2D(pool_size=(2, 2)),\n",
        "    Dropout(rate=0.2),\n",
        "    Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
        "    Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
        "    MaxPool2D(pool_size=(2, 2)),\n",
        "    Dropout(rate=0.25),\n",
        "    Flatten(),\n",
        "    Dense(units=900, activation='relu'),\n",
        "    Dropout(rate=0.5),\n",
        "    # use 43 units because there are 43 classes in the German Traffic Signals Dataset\n",
        "    Dense(units=43, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "2DqDB6bzzKYT"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use adam optimizer because it is faster than sgd and because we are using a much larger dataset than the mnist digit dataset\n",
        "# adam optimizer uses more compute resources than sgd, but it yields faster results and works better with large databases\n",
        "model.compile(\n",
        "    optimizer = 'adam',\n",
        "    loss = 'categorical_crossentropy',\n",
        "    metrics = ['accuracy']\n",
        ")\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "Leo8ZB0ZUU0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eba4800c-1779-44c2-cd03-84d43b7e1869"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_28 (Conv2D)          (None, 26, 26, 32)        2432      \n",
            "                                                                 \n",
            " conv2d_29 (Conv2D)          (None, 22, 22, 32)        25632     \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPooli  (None, 11, 11, 32)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_21 (Dropout)        (None, 11, 11, 32)        0         \n",
            "                                                                 \n",
            " conv2d_30 (Conv2D)          (None, 9, 9, 64)          18496     \n",
            "                                                                 \n",
            " conv2d_31 (Conv2D)          (None, 7, 7, 64)          36928     \n",
            "                                                                 \n",
            " max_pooling2d_15 (MaxPooli  (None, 3, 3, 64)          0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_22 (Dropout)        (None, 3, 3, 64)          0         \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 576)               0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 900)               519300    \n",
            "                                                                 \n",
            " dropout_23 (Dropout)        (None, 900)               0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 43)                38743     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 641531 (2.45 MB)\n",
            "Trainable params: 641531 (2.45 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    x_train,\n",
        "    y_train_enc,\n",
        "    epochs=20\n",
        ")"
      ],
      "metadata": {
        "id": "f6KDsucYUnV6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be178c07-a305-420e-bb28-81ce5c2aa4e7"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "988/988 [==============================] - 140s 141ms/step - loss: 1.2886 - accuracy: 0.6498\n",
            "Epoch 2/20\n",
            "988/988 [==============================] - 140s 142ms/step - loss: 0.4878 - accuracy: 0.8591\n",
            "Epoch 3/20\n",
            "988/988 [==============================] - 141s 143ms/step - loss: 0.3419 - accuracy: 0.9009\n",
            "Epoch 4/20\n",
            "988/988 [==============================] - 138s 140ms/step - loss: 0.3044 - accuracy: 0.9113\n",
            "Epoch 5/20\n",
            "988/988 [==============================] - 143s 144ms/step - loss: 0.2646 - accuracy: 0.9250\n",
            "Epoch 6/20\n",
            "988/988 [==============================] - 141s 142ms/step - loss: 0.2888 - accuracy: 0.9185\n",
            "Epoch 7/20\n",
            "988/988 [==============================] - 140s 142ms/step - loss: 0.2298 - accuracy: 0.9356\n",
            "Epoch 8/20\n",
            "988/988 [==============================] - 142s 144ms/step - loss: 0.2113 - accuracy: 0.9419\n",
            "Epoch 9/20\n",
            "988/988 [==============================] - 141s 143ms/step - loss: 0.2305 - accuracy: 0.9348\n",
            "Epoch 10/20\n",
            "988/988 [==============================] - 139s 141ms/step - loss: 0.2254 - accuracy: 0.9402\n",
            "Epoch 11/20\n",
            "988/988 [==============================] - 143s 145ms/step - loss: 0.2414 - accuracy: 0.9353\n",
            "Epoch 12/20\n",
            "988/988 [==============================] - 141s 143ms/step - loss: 0.2209 - accuracy: 0.9422\n",
            "Epoch 13/20\n",
            "988/988 [==============================] - 140s 141ms/step - loss: 0.2157 - accuracy: 0.9433\n",
            "Epoch 14/20\n",
            "988/988 [==============================] - 145s 147ms/step - loss: 0.2029 - accuracy: 0.9467\n",
            "Epoch 15/20\n",
            "988/988 [==============================] - 143s 145ms/step - loss: 0.2030 - accuracy: 0.9467\n",
            "Epoch 16/20\n",
            "988/988 [==============================] - 141s 143ms/step - loss: 0.2148 - accuracy: 0.9439\n",
            "Epoch 17/20\n",
            "988/988 [==============================] - 141s 143ms/step - loss: 0.2040 - accuracy: 0.9443\n",
            "Epoch 18/20\n",
            "988/988 [==============================] - 145s 147ms/step - loss: 0.2261 - accuracy: 0.9410\n",
            "Epoch 19/20\n",
            "988/988 [==============================] - 140s 142ms/step - loss: 0.2127 - accuracy: 0.9452\n",
            "Epoch 20/20\n",
            "988/988 [==============================] - 139s 141ms/step - loss: 0.2302 - accuracy: 0.9421\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x788940875840>"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    }
  ]
}